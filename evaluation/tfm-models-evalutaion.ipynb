{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Models evaluations\n\nThis kaggle notebook is used to evaluate the different models that have been trained. Its outputs can then serve to make comparisions and see how they perform, what parameters were used, the number of epochs or the data augmentation policy.\n\nCombined with tensorboard plots, it will also be used as the source for reporting some of the results in the final memory to deliver.\n\nIn order to get this notebook working in a cloud platform like Kaggle, we need:\n\n1. The datatet to the slices (IXI-T1-slices)\n2. The dataset or datasets to results, where .h5 NN weight and .hostory files the exist. Usually, these datasets also contain a logs folder with tensorboard data that is interpreted in Google Colab notebook (since kaggle seems to have some issues with tensorboard support)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport glob\nimport imageio\nimport random\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport math\nfrom keras import layers\nimport tensorflow_addons as tfa\nimport pickle\n\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', 1500)\npd.set_option('display.colheader_justify', 'left')\npd.set_option('display.precision', 3)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T19:16:52.878928Z","iopub.execute_input":"2021-12-19T19:16:52.879476Z","iopub.status.idle":"2021-12-19T19:16:59.421514Z","shell.execute_reply.started":"2021-12-19T19:16:52.879345Z","shell.execute_reply":"2021-12-19T19:16:59.420670Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"We need the Augmentation class to pass corrupted slices to the models and see how the results look:","metadata":{}},{"cell_type":"code","source":"class Augmentation():\n    \"\"\"\n    Helper to apply some filters to images\n    \"\"\"\n    def random(self, images):\n        # Each filter is applied with a probability of 25%, except cutout which is applied half of the times\n        if random.randint(1, 4) == 1:\n            images = self.add_noise(images)\n        if random.randint(1, 4) == 1:\n            images = self.dropout(images)\n        if random.randint(1, 4) == 1:\n            images = self.gaussian_blur(images)\n        if random.randint(1, 2) == 1:\n            images = self.cutout(images)\n        return images\n\n    def add_noise(self, images):\n        sdev = 0 + (random.random() * (0.04 - 0))\n        images = layers.GaussianNoise(stddev=sdev)(images, training=True)\n        return images\n\n    def dropout(self, images):\n        rnds_noise = tf.random.uniform((1, 2), minval=0, maxval=0.04)\n        images = tf.nn.dropout(images, rnds_noise[0][0])\n        return images\n\n    # https://www.tensorflow.org/addons/api_docs/python/tfa/image/gaussian_filter2d\n    def gaussian_blur(self, images):\n        images = tfa.image.gaussian_filter2d(images,\n                                             filter_shape=[4, 4],\n                                             sigma=0.8,\n                                             constant_values=0,\n                                             )\n        return images\n\n    def cutout(self, images):\n        w = tf.random.uniform((), minval=10, maxval=20, dtype=tf.dtypes.int32)\n        h = tf.random.uniform((), minval=10, maxval=20, dtype=tf.dtypes.int32)\n        x = tf.random.uniform((), minval=20, maxval=105, dtype=tf.dtypes.int32)\n        y = tf.random.uniform((), minval=40, maxval=105, dtype=tf.dtypes.int32)\n\n        if w % 2 != 0:\n            w += 1 if bool(random.getrandbits(1)) else -1\n        if h % 2 != 0:\n            h += 1 if bool(random.getrandbits(1)) else -1\n\n        # image = tfa.image.random_cutout(image, mask_size=(w,h), constant_values=0)\n        images = tfa.image.cutout(images,\n                                  mask_size=(w, h),\n                                  offset=(x, y),\n                                  constant_values=0\n                                  )\n        return images","metadata":{"execution":{"iopub.status.busy":"2021-12-19T19:17:10.149498Z","iopub.execute_input":"2021-12-19T19:17:10.149770Z","iopub.status.idle":"2021-12-19T19:17:10.166575Z","shell.execute_reply.started":"2021-12-19T19:17:10.149740Z","shell.execute_reply":"2021-12-19T19:17:10.165665Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"The next functions help the script visualize the results:","metadata":{}},{"cell_type":"code","source":"def get_random_images(mode=\"skull-stripped\", set='test', n=20):\n    \"\"\"\n    returns a randomly sorted list of numpy slices from a subset (test set by default)\n    \"\"\"\n    base_dir = f'../input/ixit1slices/IXI-T1-slices/{mode}/{set}'\n    files = glob.glob(f'{base_dir}/*.png')\n    random.shuffle(files)\n    files = files[0:n]\n    imgs = []\n    for file in files:\n        im = imageio.imread(file)\n        # prepare data with the same shape the NNs were fed\n        im = im.astype(np.float32)\n        im = im / 255\n        im = im.reshape(256, 256, 1)\n        imgs.append(im)\n    \n    imgs = tf.image.resize(imgs, [128, 128]).numpy()\n    return imgs\n\ndef show_img_grid(imgs, ncols=5, show_axis=False):\n    \"\"\"\n    shows a grid with ncols columns with an element in img for each resulting cell\n    \"\"\"\n    nrows = math.ceil(len(imgs) / ncols)\n    f, axarr = plt.subplots(nrows, ncols, figsize=(4*ncols,4*nrows))\n    i = 0\n       \n    for img in imgs:\n        cur_row = i // ncols\n        cur_col = i % ncols\n        if nrows == 1:\n            axarr[cur_col].imshow(np.rot90(img), cmap=\"gray\")\n            if not show_axis:\n                axarr[cur_col].axis('off')\n        else:\n            axarr[cur_row, cur_col].imshow(np.rot90(img), cmap=\"gray\")\n            if not show_axis:\n                axarr[cur_row, cur_col].axis('off')\n        i += 1\n    \ndef predict_imgs(inputs, model, augmentation=[]):\n    \"\"\"\n    predicts the input images and returns a list with pairs of images in consecutive order\n    to easily plot them\n    \"\"\"\n    if len(augmentation) > 0:\n        augment = Augmentation()\n        augmented = inputs\n        if \"noise\" in augmentation:\n            augmented = augment.add_noise(augmented)\n        if \"blur\" in augmentation:\n            augmented = augment.gaussian_blur(augmented)\n        if \"dropout\" in augmentation:\n            augmented = augment.dropout(augmented)\n        if \"cutout\" in augmentation:\n            augmented = augment.cutout(augmented)\n        if \"random\" in augmentation:\n            augmented = augment.random(augmented)\n        predicted = model.predict(augmented)\n        outputs = [None]*(len(inputs)*3)        \n        outputs[::3] = inputs\n        outputs[1::3] = augmented\n        outputs[2::3] = predicted        \n        return outputs\n    else:        \n        predicted = model.predict(inputs)\n        outputs = [None]*(len(inputs)*2)\n        outputs[::2] = inputs\n        outputs[1::2] = predicted\n        return outputs\n    \ndef show_history_data(path, show_table=True, plot=True):\n    \"\"\"\n    opens a history file generated by a model's training process. It is also possible to see the loss graphs \n    when de param. plot equals True\n    \"\"\"\n    with open(path, \"rb\") as input_file:\n        history = pickle.load(input_file)\n        \n    if show_table:\n        l = []\n        for i in range(0, len(history['loss'])):\n            l.append({'Epoch': i + 1, 'loss': history['loss'][i], 'val_loss': history['val_loss'][i] })        \n        print(pd.DataFrame(l))\n        \n    if plot:    \n        plt.style.use(\"ggplot\")\n        plt.plot(np.arange(0, len(history['loss'])), history[\"loss\"], label=\"train\")\n        plt.plot(np.arange(0, len(history['val_loss'])), history[\"val_loss\"], label=\"val\")\n        plt.title(\"Loss\")\n        plt.xlabel(\"Epoch #\")\n        plt.ylabel(\"Loss\")\n        plt.legend(loc=\"upper right\")\n        plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-19T19:17:29.157950Z","iopub.execute_input":"2021-12-19T19:17:29.158510Z","iopub.status.idle":"2021-12-19T19:17:29.180570Z","shell.execute_reply.started":"2021-12-19T19:17:29.158468Z","shell.execute_reply":"2021-12-19T19:17:29.179590Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Showing a training history\nWe can show a training history like this:","metadata":{}},{"cell_type":"code","source":"path = '../input/newgenerator/model_baseline_10epoch_es20_activation_sigmoid.h12.history'\nshow_history_data(path)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T19:17:39.423285Z","iopub.execute_input":"2021-12-19T19:17:39.423713Z","iopub.status.idle":"2021-12-19T19:17:39.700973Z","shell.execute_reply.started":"2021-12-19T19:17:39.423682Z","shell.execute_reply":"2021-12-19T19:17:39.700365Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Qualitative results\nAnd qualitative results like this:","metadata":{}},{"cell_type":"code","source":"from keras.models import load_model\nimgs = get_random_images(n=8)\npath_to_model = \"../input/newgenerator/model_baseline_10epoch_es4_activation_sigmoid.h5\"\nmodel = load_model(path_to_model)\noutputs = predict_imgs(imgs, model, ['dropout'])\nshow_img_grid(outputs, ncols=3)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T19:18:19.900014Z","iopub.execute_input":"2021-12-19T19:18:19.900823Z","iopub.status.idle":"2021-12-19T19:18:24.947624Z","shell.execute_reply.started":"2021-12-19T19:18:19.900781Z","shell.execute_reply":"2021-12-19T19:18:24.946319Z"},"trusted":true},"execution_count":6,"outputs":[]}]}