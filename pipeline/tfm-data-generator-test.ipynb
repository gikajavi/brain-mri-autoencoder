{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Generator test\n\nAfter several tests with Keras ImageDataGenerator and Custom Layers for augmentation purposes, it was decided writing a custom Data Generator. With a custom data generator we gain full control over the slices we pass to the models to be tested. Its main downside would be that is not very optimized to take advantage of a GPU (TPU) environment. However, this approach was preferred because we can easily do whatever augmentation operation we think of without having to take care of other methods constraints (this topic is elaborated in the project's memory).\n\nThis notebook shows its implementation and how can be used in an isolated manner.\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-17T19:35:32.218492Z","iopub.execute_input":"2021-12-17T19:35:32.218921Z","iopub.status.idle":"2021-12-17T19:35:38.943806Z","shell.execute_reply.started":"2021-12-17T19:35:32.218814Z","shell.execute_reply":"2021-12-17T19:35:38.942302Z"}}},{"cell_type":"code","source":"import glob\nimport numpy as np\nimport keras\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom keras import layers\nimport matplotlib.pyplot as plt\nimport cv2\nimport random\nimport imageio\nfrom keras.layers import Layer\nimport math","metadata":{"execution":{"iopub.status.busy":"2021-12-19T20:02:54.828321Z","iopub.execute_input":"2021-12-19T20:02:54.828888Z","iopub.status.idle":"2021-12-19T20:03:01.929088Z","shell.execute_reply.started":"2021-12-19T20:02:54.828784Z","shell.execute_reply":"2021-12-19T20:03:01.928356Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    \"\"\"\n    Custom class to provide data to keras models\n    AugmentationPolicy: can be => 'instance', 'batch'\n    \"\"\"\n    def __init__(self, base_dir='.', batch_size=128, Shuffle=True, Augment=True, AugmentationPolicy='instance',\n                 brain_amount=15):\n        self.batch_size = batch_size\n        self.base_dir = base_dir\n        self.shuffle = Shuffle\n        self.Augment = Augment\n        self.AugmentationPolicy = AugmentationPolicy\n        self.brain_amount = brain_amount\n\n        self.files = glob.glob(f'{base_dir}/*.png')\n        if self.brain_amount is not None:\n            self._filter_according_to_bamount()\n\n        if self.shuffle:\n            random.shuffle(self.files)\n        print(f'Data generator on {base_dir}, found {len(self.files)} PNG files')\n\n\n    def _filter_according_to_bamount(self):\n        filtered = []\n        for file in self.files:\n            ta = int(file.split('.')[-2].replace('ta', ''))\n            # ta is the number of pixels belonging to brain tissue in the original 256x256 slice\n            percentage = ta/(256*256)*100\n            if percentage > self.brain_amount:\n                filtered.append(file)\n        self.files = filtered\n\n    def __len__(self):\n        return len(self.files) // self.batch_size\n        # return math.ceil(len(self.files) / self.batch_size)\n\n    def __getitem__(self, index):\n        Y = []\n        for i in range(index * self.batch_size, index * self.batch_size + self.batch_size):\n            image_path = self.files[i]\n            im = imageio.imread(image_path)\n            im = im.astype(np.float32)\n            im = im / 255\n            im = im.reshape(256, 256, 1)\n            im = tf.image.resize(im, [128, 128])\n            Y.append(im)\n\n        # Convert Y to numpy before performing augmentation\n        Y = np.array(Y)\n\n        # Augmentation according to policy\n        if self.Augment:\n            if self.AugmentationPolicy == 'instance':\n                X = []\n                for i in range(0, len(Y)):\n                    augmented_y = self._augment(np.array([Y[i]]))\n                    X.append(augmented_y[0])\n                X = np.array(X)\n            else:\n                # All the images in batch will have the same augmentations\n                X = Y\n                X = self._augment(X)\n\n        return X, Y\n\n    #     def on_epoch_end(self):\n    #         self.indexes = np.arange(len(self.list_IDs))\n    #         if self.shuffle == True:\n    #             np.random.shuffle(self.indexes)\n\n    def _augment(self, images):\n        # Each filter is applied with a probability of 25%, except cutout which is applied half of the times\n        if random.randint(1, 4) == 1:\n            images = self.add_noise(images)\n        if random.randint(1, 4) == 1:\n            images = self.dropout(images)\n        if random.randint(1, 4) == 1:\n            images = self.gaussian_blur(images)\n        if random.randint(1, 2) == 1:\n            images = self.cutout(images)\n        return images\n\n    def add_noise(self, images):\n        sdev = 0 + (random.random() * (0.05 - 0))\n        images = layers.GaussianNoise(stddev=sdev)(images, training=True)\n        return images\n\n    def dropout(self, images):\n        rnds_noise = tf.random.uniform((1, 2), minval=0, maxval=0.04)\n        images = tf.nn.dropout(images, rnds_noise[0][0])\n        return images\n\n    # https://www.tensorflow.org/addons/api_docs/python/tfa/image/gaussian_filter2d\n    def gaussian_blur(self, images):\n        images = tfa.image.gaussian_filter2d(images,\n                                             filter_shape=[4, 4],\n                                             sigma=0.8,\n                                             constant_values=0,\n                                             )\n        return images\n\n    def cutout(self, images):\n        w = tf.random.uniform((), minval=10, maxval=20, dtype=tf.dtypes.int32)\n        h = tf.random.uniform((), minval=10, maxval=20, dtype=tf.dtypes.int32)\n        x = tf.random.uniform((), minval=20, maxval=105, dtype=tf.dtypes.int32)\n        y = tf.random.uniform((), minval=40, maxval=105, dtype=tf.dtypes.int32)\n\n        if w % 2 != 0:\n            w += 1 if bool(random.getrandbits(1)) else -1\n        if h % 2 != 0:\n            h += 1 if bool(random.getrandbits(1)) else -1\n\n        # image = tfa.image.random_cutout(image, mask_size=(w,h), constant_values=0)\n        images = tfa.image.cutout(images,\n                                  mask_size=(w, h),\n                                  offset=(x, y),\n                                  constant_values=0\n                                  )\n        return images\n","metadata":{"execution":{"iopub.status.busy":"2021-12-19T20:03:10.872287Z","iopub.execute_input":"2021-12-19T20:03:10.872634Z","iopub.status.idle":"2021-12-19T20:03:10.903794Z","shell.execute_reply.started":"2021-12-19T20:03:10.872603Z","shell.execute_reply":"2021-12-19T20:03:10.902770Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"This custom DataGenerator can augmentate images by corrupting them. The idea behind this approach is to compare the corrupted images to the ground-truth ones, trying to force the model to learn the essential features of the healthy brain. Therefore, this DataAugmentation returns a list of tuples with the corrupted ones and the ground-truth ones in order to be processed in the evalutation stage of the models' pipeline.\n\nIn the next example, we use the Data Generator in an isolated manner. We get a batch of 10 slices with augmentation. By setting the augmentation policy to 'instance' we ensure that every image in the batch has different augmentation params. This approach has the downside that we lose the oportunity to use the whole bathc as a tensor to be processed in parallel. This behaviour can be achieved by passing AugmentationPolicy='batch', though.","metadata":{}},{"cell_type":"code","source":"dg = DataGenerator(batch_size=10, base_dir='../input/ixit1slices/IXI-T1-slices/skull-stripped/test', AugmentationPolicy='instance')\ngen = dg[1]\n\nimgs_augmented = gen[0]\nfor i in range(0,len(imgs_augmented)):\n    print(i)\n    plt.imshow(imgs_augmented[i])\n    plt.gray()\n    plt.show()\n    \nimgs_orig = gen[1]\nfor i in range(0,len(imgs_orig)):\n    print(i)\n    plt.imshow(imgs_orig[i])\n    plt.gray()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T20:03:28.872556Z","iopub.execute_input":"2021-12-19T20:03:28.872878Z","iopub.status.idle":"2021-12-19T20:03:33.123295Z","shell.execute_reply.started":"2021-12-19T20:03:28.872848Z","shell.execute_reply":"2021-12-19T20:03:33.122335Z"},"trusted":true},"execution_count":4,"outputs":[]}]}