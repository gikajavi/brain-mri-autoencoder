{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Experiment tests\n\nThis notebook shows how to perform an experiment. To do an experiment we need:\n\n- The dataset with the IXI-T1 slices\n- The DataGenerator class that helps the Experiment with data acquisition and data augmentation\n- The autoencoder model\n- The Experiment() class. This class is not compulsory but is useful to help us get the results and pass the hyperparemeters. It is also useful to obtain the results of the experiment in a homogenous way, so that each test has a uniform output structure, which can then be used as the input in the evaluation stages of the project.\n\nIn this project, the experiments were run inside Kaggle kernels. Even though Kaggle offers the possibility to use \"Utility scripts\", we declined this option, so we need to include the models to use inline, as well as the Experiment() class itself and other dependencies such as a custom data generator.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# Library dependencies\nimport numpy as np\nimport glob\nimport traceback\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport random\nimport keras\nfrom keras import layers\nimport imageio\nimport pickle\nfrom data_generator import DataGenerator","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The Experiment class\nThe experiment class works as a wrapper of common keras operations. Despite losing most of the keras utilities, we focus on the problem we are facing and thus we can only pass a limited list of hyperparameters that we think that could be important for our task. Some of these params. are the model, the number of epochs or the batch_size.\n\nThe instances of Experiment() write a homogenous output which consists of:\n\n- A logs folder that can be interpreted by tensorboard\n- A .history file, containing the summary of losses and metrics for each epoch\n- A .h5 containing the architecture and the weights calculated during the training stage","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:14:31.659061Z","iopub.execute_input":"2021-12-19T21:14:31.659363Z","iopub.status.idle":"2021-12-19T21:14:31.663697Z","shell.execute_reply.started":"2021-12-19T21:14:31.659331Z","shell.execute_reply":"2021-12-19T21:14:31.662681Z"}}},{"cell_type":"code","source":"class Experiment:\n    _history = None\n\n    def __init__(self, name='Exp', model: keras.Model = None, da_enabled=True, aug_policy='batch', train_gen=None, val_gen=None,\n                 skull_stripped=True, path_to_dataset='', path_to_results='', epochs=25, es_patience=5,\n                 batch_size=128, optimizer=\"Adam\", loss=\"mse\", metrics=\"mse\", reduce_lr_on_plateau=True):\n        self.name = name\n        self.model = model\n        self.da_enabled = da_enabled\n        self.aug_policy = aug_policy\n        self.train_gen = train_gen\n        self.val_gen = val_gen\n        self.skull_stripped = skull_stripped\n        self.path_to_dataset = path_to_dataset\n        self.path_to_results = path_to_results\n        self.epochs = epochs\n        self.es_patience = es_patience\n        self.batch_size = batch_size\n        self.optimizer = optimizer\n        self.loss = loss\n        self.metrics = metrics\n        self.reduce_lr_on_plateau = reduce_lr_on_plateau\n\n        if self.path_to_dataset == '':\n            self.path_to_dataset = '../input/ixit1slices/IXI-T1-slices'\n        if self.path_to_results == '':\n            self.path_to_results = './'\n\n        path_to_slices = '/skull-stripped' if self.skull_stripped else '/full'\n        path_to_slices = self.path_to_dataset + path_to_slices\n        path_to_train_slices = path_to_slices + '/train'\n        path_to_val_slices = path_to_slices + '/val'\n\n        self.train_gen = DataGenerator(base_dir=path_to_train_slices, batch_size=self.batch_size,\n                                       Augment=self.da_enabled, AugmentationPolicy=self.aug_policy)\n\n        self.val_gen = DataGenerator(base_dir=path_to_val_slices, batch_size=self.batch_size,\n                                     Augment=self.da_enabled, AugmentationPolicy=self.aug_policy)\n\n    def get_name(self):\n        \"\"\"\n        The name of this experiment, which depends on the model's name and some of the experiment parameters\n        :return:\n        \"\"\"\n        da_config: str = 'da-yes' if self.da_enabled else 'da-no'\n        skull_mode: str = 'skull-stripped' if self.skull_stripped else 'full-skull'\n        rlronplateru = 'rlrop-Y' if self.reduce_lr_on_plateau else 'rlrop-N'\n        return f'{self.name}_model-{self.model.name}_{skull_mode}_ep-{self.epochs}_bs-{self.batch_size}_{da_config}_loss-{self.loss}_{rlronplateru}'\n\n    def start(self):\n        \"\"\"\n        starts the experirment with the given params\n        :return:\n        \"\"\"\n        try:\n            print('Experiment started')\n            if self.model is None:\n                raise Exception(\"No Model was provided\")\n\n            print(\"Model is about to start training\")\n            self.fit_model()\n\n            print(\"Training has finished. Saving results.\")\n            self.save_results()\n        except Exception as ex:\n            print(\"General error executing the experiment: \" + str(ex))\n            print(traceback.format_exc())\n\n    def fit_model(self):\n        self.compile_model()\n\n        # Callbacks\n        callbacks = []\n        callbacks.append(tf.keras.callbacks.TensorBoard(f\"logs/{self.get_name()}\"))\n        callbacks.append(keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=self.es_patience,\n                                                       verbose=1, restore_best_weights=True))\n        if self.reduce_lr_on_plateau:\n            callbacks.append(tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2,\n                                                                  patience=2, verbose=1, cooldown=1))\n\n        self._history = self.model.fit(self.train_gen,\n                                       epochs=self.epochs,\n                                       batch_size=self.batch_size,\n                                       validation_data=self.val_gen,\n                                       callbacks=callbacks)\n\n    def compile_model(self):\n        loss_func = self.get_loss_function()\n        self.model.compile(loss=loss_func, optimizer=self.optimizer, metrics=self.metrics)\n\n    def get_loss_function(self):\n        if self.loss == 'ssim':\n            return self._loss_ssim\n        elif self.loss == 'ms-ssim':\n            return self._loss_ms_ssim\n        elif self.loss == 'combined':\n            return self._loss_mae_ssim\n        else:\n            return 'mse'\n\n    def _loss_ssim(self, img, pred_img):\n        return 1 - tf.reduce_mean(tf.image.ssim(pred_img, img, 1.0))\n\n    def _loss_ms_ssim(self, img, pred_img):\n        return 1 - tf.reduce_mean(tf.image.ssim_multiscale(pred_img, img, 1.0))\n\n    def _loss_mae_ssim(self, img, pred_img):\n        # https://arxiv.org/pdf/1511.08861.pdf\n        # TODO\n        return None\n\n\n    def save_results(self):\n        filename = self.path_to_results + self.get_name() + '.h5'\n        self.model.save(filename)\n\n        filename = self.path_to_results + self.get_name() + '.history'\n        with open(filename, 'wb') as file_pi:\n            pickle.dump(self._history.history, file_pi)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The model\nWe need to include the model architecture or architectures we want to use in our experiments. In this example, we include the Convolutional Autoencoder based on residual blocks fith pre activation and skip connections.\n\n","metadata":{}},{"cell_type":"code","source":"class resnet_model():\n    def get_model(self, activation='sigmoid', type='pre'):\n        input_img = layers.Input(shape=(128, 128, 1))\n\n        res_block = self._pre_activation_residual_block if type == 'pre' else residual_block\n        conv2d = layers.Conv2D(32, (3, 3), strides=2, padding=\"same\", name='Conv1')(input_img)\n        resblock = res_block(conv2d, 64)\n        resblock = res_block(resblock, 64, strides=1)\n        encoder = res_block(resblock, 128, strides=2)\n\n        decoder = self._transpose2d(encoder, 64)\n        decoder = layers.Concatenate()([decoder, resblock])\n        decoder = self._transpose2d(decoder, 32)\n        decoder = layers.Concatenate()([decoder, conv2d])\n        decoder = self._transpose2d(decoder, 16)\n        decoder = layers.Conv2D(1, (3, 3), activation=activation, padding='same')(decoder)\n\n        return Model(input_img, decoder, name=\"resnet_\" + type)\n\n    def _transpose2d(self, inputs, filters):\n        block = layers.Conv2DTranspose(filters, (3, 3), strides=(2, 2), padding='same')(inputs)\n        block = layers.BatchNormalization()(block)\n        block = layers.ReLU()(block)\n        return block\n\n    def _residual_block(self, inputs, filters, strides=2):\n        \"\"\"\n        See the block diagram:\n        https://www.researchgate.net/figure/Architecture-of-normal-residual-block-a-and-pre-activation-residual-block-b_fig2_337691625\n        \"\"\"\n        block = layers.Conv2D(filters=filters, kernel_size=(3, 3), strides=strides, padding=\"same\")(inputs)\n        block = layers.BatchNormalization()(block)\n        block = layers.ReLU()(block)\n\n        block = layers.Conv2D(filters=filters, kernel_size=(3, 3), strides=1, padding=\"same\")(block)\n        block = layers.BatchNormalization()(block)\n\n        inputs = layers.Conv2D(filters=filters, kernel_size=(1, 1), strides=strides, padding=\"same\")(inputs)\n\n        block = layers.Add()([inputs, block])\n        block = layers.ReLU()(block)\n        return block\n\n    def _pre_activation_residual_block(self, inputs, filters, strides=2):\n        \"\"\"\n        See the block diagram:\n        https://www.researchgate.net/figure/Architecture-of-normal-residual-block-a-and-pre-activation-residual-block-b_fig2_337691625\n        \"the pre-activation architecture is implemented by moving BN and ReLU activation function before convolution operation\"\n        \"\"\"\n        block = layers.BatchNormalization()(inputs)\n        block = layers.ReLU()(block)\n\n        block = layers.Conv2D(filters=filters, kernel_size=(3, 3), strides=strides, padding=\"same\")(block)\n\n        block = layers.BatchNormalization()(block)\n        block = layers.ReLU()(block)\n\n        block = layers.Conv2D(filters=filters, kernel_size=(3, 3), strides=1, padding=\"same\")(block)\n\n        if strides != 1:\n            inputs = layers.Conv2D(filters=filters, kernel_size=(1, 1), strides=strides, padding=\"same\")(inputs)\n\n        block = layers.Add()([inputs, block])\n        return block","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Experiment() class relies on the DataGenerator() class, a custom keras data generator specific for this project:","metadata":{}},{"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    \"\"\"\n    Custom class to provide data to keras models\n    AugmentationPolicy: can be => 'instance', 'batch'\n    \"\"\"\n    def __init__(self, base_dir='.', batch_size=128, Shuffle=True, Augment=True, AugmentationPolicy='instance',\n                 brain_amount=15):\n        self.batch_size = batch_size\n        self.base_dir = base_dir\n        self.shuffle = Shuffle\n        self.Augment = Augment\n        self.AugmentationPolicy = AugmentationPolicy\n        self.brain_amount = brain_amount\n\n        self.files = glob.glob(f'{base_dir}/*.png')\n        if self.brain_amount is not None:\n            self._filter_according_to_bamount()\n\n        if self.shuffle:\n            random.shuffle(self.files)\n        print(f'Data generator on {base_dir}, found {len(self.files)} PNG files')\n\n\n    def _filter_according_to_bamount(self):\n        filtered = []\n        for file in self.files:\n            ta = int(file.split('.')[-2].replace('ta', ''))\n            # ta is the number of pixels belonging to brain tissue in the original 256x256 slice\n            percentage = ta/(256*256)*100\n            if percentage > self.brain_amount:\n                filtered.append(file)\n        self.files = filtered\n\n    def __len__(self):\n        return len(self.files) // self.batch_size\n        # return math.ceil(len(self.files) / self.batch_size)\n\n    def __getitem__(self, index):\n        Y = []\n        for i in range(index * self.batch_size, index * self.batch_size + self.batch_size):\n            image_path = self.files[i]\n            im = imageio.imread(image_path)\n            im = im.astype(np.float32)\n            im = im / 255\n            im = im.reshape(256, 256, 1)\n            im = tf.image.resize(im, [128, 128])\n            Y.append(im)\n\n        # Convert Y to numpy before performing augmentation\n        Y = np.array(Y)\n\n        # Augmentation according to policy\n        if self.Augment:\n            if self.AugmentationPolicy == 'instance':\n                X = []\n                for i in range(0, len(Y)):\n                    augmented_y = self._augment(np.array([Y[i]]))\n                    X.append(augmented_y[0])\n                X = np.array(X)\n            else:\n                # All the images in batch will have the same augmentations\n                X = Y\n                X = self._augment(X)\n\n        return X, Y\n\n    #     def on_epoch_end(self):\n    #         self.indexes = np.arange(len(self.list_IDs))\n    #         if self.shuffle == True:\n    #             np.random.shuffle(self.indexes)\n\n    def _augment(self, images):\n        # Each filter is applied with a probability of 25%, except cutout which is applied half of the times\n        if random.randint(1, 4) == 1:\n            images = self.add_noise(images)\n        if random.randint(1, 4) == 1:\n            images = self.dropout(images)\n        if random.randint(1, 4) == 1:\n            images = self.gaussian_blur(images)\n        if random.randint(1, 2) == 1:\n            images = self.cutout(images)\n        return images\n\n    def add_noise(self, images):\n        sdev = 0 + (random.random() * (0.05 - 0))\n        images = layers.GaussianNoise(stddev=sdev)(images, training=True)\n        return images\n\n    def dropout(self, images):\n        rnds_noise = tf.random.uniform((1, 2), minval=0, maxval=0.04)\n        images = tf.nn.dropout(images, rnds_noise[0][0])\n        return images\n\n    # https://www.tensorflow.org/addons/api_docs/python/tfa/image/gaussian_filter2d\n    def gaussian_blur(self, images):\n        images = tfa.image.gaussian_filter2d(images,\n                                             filter_shape=[4, 4],\n                                             sigma=0.8,\n                                             constant_values=0,\n                                             )\n        return images\n\n    def cutout(self, images):\n        w = tf.random.uniform((), minval=10, maxval=20, dtype=tf.dtypes.int32)\n        h = tf.random.uniform((), minval=10, maxval=20, dtype=tf.dtypes.int32)\n        x = tf.random.uniform((), minval=20, maxval=105, dtype=tf.dtypes.int32)\n        y = tf.random.uniform((), minval=40, maxval=105, dtype=tf.dtypes.int32)\n\n        if w % 2 != 0:\n            w += 1 if bool(random.getrandbits(1)) else -1\n        if h % 2 != 0:\n            h += 1 if bool(random.getrandbits(1)) else -1\n\n        # image = tfa.image.random_cutout(image, mask_size=(w,h), constant_values=0)\n        images = tfa.image.cutout(images,\n                                  mask_size=(w, h),\n                                  offset=(x, y),\n                                  constant_values=0\n                                  )\n        return images\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Up to this point, the above code is not new, since it was already introduced in other notebooks. The actual code that gets everything working consists of getting an instance of Experiment() and passing the appropriate parameters to then running the process:","metadata":{}},{"cell_type":"code","source":"exp = Experiment(bath_size=64, epochs = 20, da_enabled = True, skull_stripped = True, es_patience = 5)\nexp.model = resnet_model().get_model()\nexp.start()","metadata":{},"execution_count":null,"outputs":[]}]}