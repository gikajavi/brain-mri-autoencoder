# Brain MRI Autoencoder
UOC TFM - An attempt to build a deep learning autoencoder based on 2D slices from MRIs from healthy brains

# Summary of the files
The project is structured in 3 main folders:
- pre-processing/
- pipeline/
- evaluation/
## Pre-processing folder
The pre-processing folder contains Python scripts and Kaggle notebooks that were used during the exploration and pre-processing stage of the project.

**Relevant files:**
- tfm-ds-exploration.ipynb: The initial notebook where the initial dataset (IXI-T1) is explored to get the first impressions and insights.
- tfm-segmentation-with-deepbrain.ipynb: Inspired by previous UOC projects, we decided to evaluate and finally use the deepbrain segmentation tool. This notebook generates deepbrain masks from NIFTI files that will be later used.
- tfm-slicer.ipynb: This project works with pre-generated slices from NIFTI volumes. This notebook is responsible for acquiring them, both for original full-skull versions and for the segmented skull-stripped ones.
## Pipeline folder
The pipeline folder contains Python scripts and Kaggle notebooks that were used to implement the models and perform the experiments.

**Relevant files:**
- tfm-data-generator-test.ipynb: This notebook demonstrates how to use a custom data generator class that is used in the project and is coded in the data_generator.py script.
- tfm-experiment-tests.ipynb: This notebook is an example of how to use this codebase to perform end-to-end experiments in a cloud platform Kaggle with GPU support.
- baseline_model.py, skconn_model.py, resnet_sconns_model.py: These 3 files contain keras models for 3 different convolutional autoencoders.
## Evaluation folder
The evaluation folder contains Python scripts and Kaggle notebooks that are used in the last stage of the project, consisting in assessing the modelsâ€™ results and making comparisons between them. Some of the conclusions in the final report will be directly extracted from data generated by the scripts in this folder.

**Relevant files:**
- tfm-augmentation-testing.ipynb: This notebook shows some examples on how to use the data augmentation techniques included in the project. Despite being part of the data acquisition stage (pipeline), data augmentation is also used in evaluation in order to corrupt test images before predicting them with trained models.
- tfm-models-evaluation.ipynb: This notebook contains a set of tools that are useful to evaluate the performance of all the models and different variants. As aforementioned, these results will be used in the final report to explain the conclusions and to show examples.
